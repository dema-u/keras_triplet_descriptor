{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineCodeTest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dema-u/keras_triplet_descriptor/blob/master/BaselineCodeTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dOhc9s5YEtHR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GPU CHECKS AND IMPORTING DATA"
      ]
    },
    {
      "metadata": {
        "id": "2DoIqHXhE4VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1720
        },
        "outputId": "c6dd3aa7-ec5d-4d7c-e287-314a873439bb"
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "!pip install talos\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "  \n",
        "printm()\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import talos\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, Conv3D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "from keras.activations import sigmoid, relu, elu\n",
        "from keras.layers.convolutional import Deconvolution2D\n",
        "from talos import live, Reporting\n",
        "from talos.model.normalizers import lr_normalizer\n",
        "from keras.losses import mean_squared_error, binary_crossentropy\n",
        "\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor\n",
        "  \n",
        "%cd /content/keras_triplet_descriptor  \n",
        "\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
        "  \n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip\n",
        "\n",
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs))\n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
        "\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python2.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: talos in /usr/local/lib/python2.7/dist-packages (0.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from talos) (1.14.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from talos) (2.18.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages (from talos) (2.2.4)\n",
            "Requirement already satisfied: chances in /usr/local/lib/python2.7/dist-packages (from talos) (0.1.4)\n",
            "Requirement already satisfied: kerasplotlib in /usr/local/lib/python2.7/dist-packages (from talos) (0.1.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: astetik in /usr/local/lib/python2.7/dist-packages (from talos) (1.9.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (from talos) (0.22.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (from talos) (4.28.1)\n",
            "Requirement already satisfied: wrangle in /usr/local/lib/python2.7/dist-packages (from talos) (0.6.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->talos) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->talos) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->talos) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from keras->talos) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from keras->talos) (1.0.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras->talos) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras->talos) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras->talos) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras->talos) (1.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn->talos) (0.20.3)\n",
            "Requirement already satisfied: geonamescache in /usr/local/lib/python2.7/dist-packages (from astetik->talos) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python2.7/dist-packages (from pandas->talos) (2.5.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python2.7/dist-packages (from wrangle->talos) (0.8.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python2.7/dist-packages (from statsmodels->wrangle->talos) (0.5.1)\n",
            "('RAM Free: 11.5 GB', ' | Proc size: 151.4 MB')\n",
            "GPU RAM Free: 9257MB | Used: 2184MB | Util  19% | Total 11441MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n",
            "/usr/local/lib/python2.7/dist-packages/chances/plots.py:7: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
            "    \"__main__\", fname, loader, pkg_name)\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
            "    exec code in run_globals\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"</usr/local/lib/python2.7/dist-packages/decorator.pyc:decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1422, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras_triplet_descriptor' already exists and is not an empty directory.\n",
            "/content/keras_triplet_descriptor\n",
            "--2019-03-07 17:13:11--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 185.235.236.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|185.235.236.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-07 17:13:11--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-07 17:13:12--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 185.235.236.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|185.235.236.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!15JyEOG8NUBXWuySygoCRKpB1EMeKvYb057lEnoXRaRioSVVRWRs0VfMV8M_LevhxdkFy9DdnqUI6FRXZV_y2I6DVQCw52qg3-K9Zww1Yrr2cDaKZ_cVdMNaXGxaX4XFu0TnvTkli8jijpV13CzRURMnT5mxYyMOTB8aLwOnWSLq8tUZztZHBsxm3lJb6CUqMNEHyDckixFiobagTP-wuCUNaWMGiKU6g-LF_l6vh1QCHtfpM0xJHaUs57Tdu65y32jlQDHOWZr5_Q1aWg39iuJ7OUuICO1UgcQ5lg-2HC9RLJ5E5pbHgjrYjnjTAic_BfmAEFx5BnjEpRdcDD8GPv5yxOm1vfCxUu2YtkXo-Kpbl14C_BwL_NRWPKQjh5ARidN9bbzfZEDXHE9Eyh02CkTwo2_mvVrfLxkjasJut37uR6n6M1ftPZ1dlHFl7AjGyI4JRlxcdleKnYagIZptWqeOJprW__na5dFjXTq_tJqGQhLIK8LDGc6Xgsr8DOEmgCVP1FEeArSN1AOwlj2QAAK57K0nmR72wk1nsyBZA6n3Ug29vfVWjk8XjDRq-uimhZbojN8sGTnzKwNiahxzT4MGIoyvQcnbea_VDL7KDyp05DsvlfMk9YDgRdhtz77lVl1jC8W48pEqCs7CzHaemEmw3P5KeSt2VoDxdJYwaWTKMZh-yHoSz_HVkQC_qoZ6OuWUIY6d-FfOt4A8mXRlUziRLWGiOVZcYHXJlBg82xJY0mWVKee7vX9dVSfWKmIVdD8O2kr9_feQG2HhAx8DGpcmUeTIa2Bt83lB_lNcqP_dlj9cxSeM_Q4_5HzIT1uUcUbtlC69oYiGgm4OVI8k6hrFLZdAH2rKtfat2sFiGswVHxVQd9S-QdN3qcDdOZXwjCSj1qfmnJJQYo8yAiAhRGnM8lvS61jvz1yoY9PU3cc-DpHU1H1sWG-IajBLqXrfcP3TN0TgHVF2tyqjQughoLzlU5JAqloDrOaqx_Q0dJ_0Tjk8bbNu3RJYSjFe_Fe_hDYGgR5yDZseqCFFMhOXi8E8kekZGzGI8kwCTXAmowfTsEHjIAZ81TkWzeHqjLsnptoGQGg7UuCfipSHX67Qto6VfCVbmimwayar3J6vP0fTVBHlyg60Pm6Acu0QEoJ1lwRQRurJ_jt0EZHaMqPAWubKkP8BsnVYboGx2kXI7_VbFOGAWr4v9tf3eWwBlPC-Cc2MFJq6fHLqBuD988bNc2GeCR0EqJNwQoae1MpVJlHdSnwKPrrw642ouH5Sy5rRYjAibwYdo2gysdGwjaufTCQgXIgLILrjstuIDWBapXjXwKbTRTHX5cMRrls51fDkSEmaHiUpuW5KGDwhJIFoeDSZmXH3PgtZ4F9lDg8W_06EKav5LyIpd6SgyKEcVZNMmaMvK-sFNkXPA_ZR09f-4nsFTc15FDeFPCuw9cxwcjIp9JMGCSSh939voYNw99-FbQ3KIAGW5ohdsRLdK4dN2g4IDPPrT5u03dgDBQ../download [following]\n",
            "--2019-03-07 17:13:12--  https://public.boxcloud.com/d/1/b1!15JyEOG8NUBXWuySygoCRKpB1EMeKvYb057lEnoXRaRioSVVRWRs0VfMV8M_LevhxdkFy9DdnqUI6FRXZV_y2I6DVQCw52qg3-K9Zww1Yrr2cDaKZ_cVdMNaXGxaX4XFu0TnvTkli8jijpV13CzRURMnT5mxYyMOTB8aLwOnWSLq8tUZztZHBsxm3lJb6CUqMNEHyDckixFiobagTP-wuCUNaWMGiKU6g-LF_l6vh1QCHtfpM0xJHaUs57Tdu65y32jlQDHOWZr5_Q1aWg39iuJ7OUuICO1UgcQ5lg-2HC9RLJ5E5pbHgjrYjnjTAic_BfmAEFx5BnjEpRdcDD8GPv5yxOm1vfCxUu2YtkXo-Kpbl14C_BwL_NRWPKQjh5ARidN9bbzfZEDXHE9Eyh02CkTwo2_mvVrfLxkjasJut37uR6n6M1ftPZ1dlHFl7AjGyI4JRlxcdleKnYagIZptWqeOJprW__na5dFjXTq_tJqGQhLIK8LDGc6Xgsr8DOEmgCVP1FEeArSN1AOwlj2QAAK57K0nmR72wk1nsyBZA6n3Ug29vfVWjk8XjDRq-uimhZbojN8sGTnzKwNiahxzT4MGIoyvQcnbea_VDL7KDyp05DsvlfMk9YDgRdhtz77lVl1jC8W48pEqCs7CzHaemEmw3P5KeSt2VoDxdJYwaWTKMZh-yHoSz_HVkQC_qoZ6OuWUIY6d-FfOt4A8mXRlUziRLWGiOVZcYHXJlBg82xJY0mWVKee7vX9dVSfWKmIVdD8O2kr9_feQG2HhAx8DGpcmUeTIa2Bt83lB_lNcqP_dlj9cxSeM_Q4_5HzIT1uUcUbtlC69oYiGgm4OVI8k6hrFLZdAH2rKtfat2sFiGswVHxVQd9S-QdN3qcDdOZXwjCSj1qfmnJJQYo8yAiAhRGnM8lvS61jvz1yoY9PU3cc-DpHU1H1sWG-IajBLqXrfcP3TN0TgHVF2tyqjQughoLzlU5JAqloDrOaqx_Q0dJ_0Tjk8bbNu3RJYSjFe_Fe_hDYGgR5yDZseqCFFMhOXi8E8kekZGzGI8kwCTXAmowfTsEHjIAZ81TkWzeHqjLsnptoGQGg7UuCfipSHX67Qto6VfCVbmimwayar3J6vP0fTVBHlyg60Pm6Acu0QEoJ1lwRQRurJ_jt0EZHaMqPAWubKkP8BsnVYboGx2kXI7_VbFOGAWr4v9tf3eWwBlPC-Cc2MFJq6fHLqBuD988bNc2GeCR0EqJNwQoae1MpVJlHdSnwKPrrw642ouH5Sy5rRYjAibwYdo2gysdGwjaufTCQgXIgLILrjstuIDWBapXjXwKbTRTHX5cMRrls51fDkSEmaHiUpuW5KGDwhJIFoeDSZmXH3PgtZ4F9lDg8W_06EKav5LyIpd6SgyKEcVZNMmaMvK-sFNkXPA_ZR09f-4nsFTc15FDeFPCuw9cxwcjIp9JMGCSSh939voYNw99-FbQ3KIAGW5ohdsRLdK4dN2g4IDPPrT5u03dgDBQ../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  21.4MB/s    in 3m 7s   \n",
            "\n",
            "2019-03-07 17:16:20 (20.8 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n",
            "replace hpatches/v_man/e3.anisjitter? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q0oR5fuTFC7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TESTING BASELINE CODE"
      ]
    },
    {
      "metadata": {
        "id": "jdXgEq-VFGEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4abaf62d-b91c-402b-c605-94be858ccc87"
      },
      "cell_type": "code",
      "source": [
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4RsaOCeFOB7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model_baseline(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder starts\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "    \n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv4)\n",
        "  \n",
        "  return shallow_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrM65kW5Ghg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model_baseline(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  \n",
        "  up3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv3))\n",
        "  merge3 = concatenate([conv2,up3], axis = -1)\n",
        "  up4 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(merge3))\n",
        "  merge4 = concatenate([conv1,up4], axis = -1)\n",
        "  conv4 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge4)\n",
        "    \n",
        "  conv5 = Conv2D(1, 3,  padding = 'same')(conv4)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv5)\n",
        "  \n",
        "  return shallow_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uueQvywiTlB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d98ed005-1072-434b-ddf3-22fd8035d35a"
      },
      "cell_type": "code",
      "source": [
        "get_denoise_model_baseline((32, 32, 1)).summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 16)   160         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 16)   0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 32, 32, 32)   0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 64)   8256        up_sampling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 80)   0           conv2d_37[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 64)   46144       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 1)    577         conv2d_40[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 59,777\n",
            "Trainable params: 59,777\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8iV0GlUFUf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3fa13db-412d-46e9-8917-720f770d6f4d"
      },
      "cell_type": "code",
      "source": [
        "try: del denoise_model_baseline; print(\"Deleted previous model. Compiling a new one...\")\n",
        "except: print(\"The model has not been initialized. Compiling...\")\n",
        "\n",
        "shape = (32, 32, 1)\n",
        "denoise_model_baseline = get_denoise_model_baseline(shape)\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model_baseline.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleted previous model. Compiling a new one...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pMvg244sFWwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "45afa30e-b333-491e-8ce4-4862b6220d1c"
      },
      "cell_type": "code",
      "source": [
        "denoise_history_baseline = denoise_model_baseline.fit_generator(generator=denoise_generator, epochs=10, verbose=1, validation_data=denoise_generator_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1718/1718 [==============================] - 61s 35ms/step - loss: 9.9069 - mean_absolute_error: 9.9069 - val_loss: 7.3893 - val_mean_absolute_error: 7.3893\n",
            "Epoch 2/10\n",
            " 816/1718 [=============>................] - ETA: 30s - loss: 8.1179 - mean_absolute_error: 8.1179"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWUx4BZ0FZYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2,1)\n",
        "axes[0].plot(denoise_history_baseline.history['mean_absolute_error'], 'r')\n",
        "axes[0].set_title('De-noise Model Training Loss')\n",
        "axes[0].set_ylabel('Mean Average Error (%)')\n",
        "axes[0].set_xlabel('Number of epochs')\n",
        "\n",
        "fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "axes[1].plot(denoise_history_baseline.history['val_mean_absolute_error'], 'g')\n",
        "axes[1].set_title('De-noise Model Validation Loss')\n",
        "axes[1].set_ylabel('Mean Average Error (%)')\n",
        "axes[1].set_xlabel('Number of epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3BESwJfFruQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames, denoise_model=denoise_model_baseline, use_clean=False)\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzD68jizF5BA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_descriptor_model_baseline(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "\n",
        "def triplet_loss_baseline(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbX0WAsjFyzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try: del descriptor_model_baseline; print(\"Deleted previous model. Compiling a new one...\")\n",
        "except: print(\"The model has not been initialized. Compiling...\")\n",
        "\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model_baseline = get_descriptor_model_baseline(shape)\n",
        "ea = descriptor_model_baseline(xa)\n",
        "ep = descriptor_model_baseline(xp)\n",
        "en = descriptor_model_baseline(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss_baseline)([ea, ep, en])\n",
        "\n",
        "descriptor_model_baseline = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_baseline.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgeuC8JjF99N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "descriptor_history_baseline = descriptor_model_baseline.fit_generator(generator=training_generator, epochs=10, verbose=1, validation_data=val_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8e3jSwdGAdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,1)\n",
        "axes[0].plot(descriptor_history_baseline.history['loss'], 'r')\n",
        "axes[0].set_title('De-noise Model Training Loss')\n",
        "axes[0].set_ylabel('Error (%)')\n",
        "axes[0].set_xlabel('Number of epochs')\n",
        "\n",
        "fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "axes[1].plot(descriptor_history_baseline.history['val_loss'], 'g')\n",
        "axes[1].set_title('De-noise Model Validation Loss')\n",
        "axes[1].set_ylabel('Error (%)')\n",
        "axes[1].set_xlabel('Number of epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72UycEmTGC-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model_baseline, seqs_test, denoise_model = denoise_model_baseline, use_clean=False)\n",
        "\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n",
        "\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n",
        "\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}